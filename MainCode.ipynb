{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreenidhi-Kovai-Sivabalan/Fake-News-Detection/blob/main/MainCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing Coursework"
      ],
      "metadata": {
        "id": "PXe1R9BzeYk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76PnOn6qdqA1"
      },
      "outputs": [],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VLrpGHRSevfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "data = load_dataset('ErfanMoosaviMonazzah/fake-news-detection-dataset-English')\n",
        "\n",
        "# Splitting the dataset as training set, validation set and test set\n",
        "data_train = pd.DataFrame(data['train'])\n",
        "data_val = pd.DataFrame(data['validation'])\n",
        "data_test = pd.DataFrame(data['test'])"
      ],
      "metadata": {
        "id": "gzm_FYN8fDZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of each set\n",
        "print(f'Train data shape: {data_train.shape}')\n",
        "print(f'Validation data shape: {data_val.shape}')\n",
        "print(f'Test data shape: {data_test.shape}')"
      ],
      "metadata": {
        "id": "_drokbdLfkq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train size: {len(data_train)}\")\n",
        "print(f\"Validation size: {len(data_val)}\")\n",
        "print(f\"Test size: {len(data_test)}\")"
      ],
      "metadata": {
        "id": "RMdE55ZRgXOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.head()"
      ],
      "metadata": {
        "id": "YLfoi3pMghMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "rMDFG6aphE9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nTg-_mz_gj-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values\n",
        "print(f\"Missing values in train data:\\n{data_train.isnull().sum()}\")"
      ],
      "metadata": {
        "id": "xTUvPT8OhoEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Distribution in Train Data\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='label', data=data_train)\n",
        "plt.title('Class Distribution in Train Data')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(ticks=[0, 1], labels=['Real', 'Fake'], rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Su0OicukipMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = data_train['label'].value_counts()\n",
        "class_counts\n",
        "\n",
        "# The dataset is not imbalanced so class balancing techniques like\n",
        "# SMOTE, BorderlineSMOTE, ADASYN don't have to applied."
      ],
      "metadata": {
        "id": "Sh5DNymIkYfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse test length - number of words\n",
        "data_train['text_length'] = data_train['text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(data_train['text_length'], bins=30, kde=True)\n",
        "plt.title('Distribution of Text Length in Train Data')\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nSDlXstoi6xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text for real and fake news articles\n",
        "print('Sample real news article:\\n')\n",
        "print(data_train[data_train['label'] == 0]['text'].iloc[0])\n",
        "print('\\nSample fake news article:\\n')\n",
        "print(data_train[data_train['label'] == 1]['text'].iloc[0])"
      ],
      "metadata": {
        "id": "opV9G17djagr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "UdB7jLgkoxNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "zaOczfNDpTKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "xlyOBGgJpraM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_text(text):\n",
        "  text = text.lower() # converting the text into lower case\n",
        "  text = re.sub(r'[^a-z\\s]', '', text) # removing unwanted characters - punctuation, numbers, speacial characters\n",
        "  tokens = word_tokenize(text) # tokenisation\n",
        "  filtered_tokens = [token for token in tokens if token not in stop_words] # removing stop words\n",
        "  cleaned_text = ' '.join(filtered_tokens)\n",
        "  return cleaned_text"
      ],
      "metadata": {
        "id": "V_BqFsjfrH77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the preprocessing steps to the dataset\n",
        "data_train['cleaned_text'] = data_train['text'].apply(preprocessing_text)\n",
        "data_val['cleaned_text'] = data_val['text'].apply(preprocessing_text)\n",
        "data_test['cleaned_text'] = data_test['text'].apply(preprocessing_text)"
      ],
      "metadata": {
        "id": "ErOxz__osnhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample of Preprocessed Real News Article\n",
        "print('Sample preprocessed real news article:\\n')\n",
        "data_train[data_train['label'] == 0].iloc[0]['cleaned_text']"
      ],
      "metadata": {
        "id": "ex4Nk2QGsv88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample of Preprocessed Fake News Article\n",
        "print('\\nSample preprocessed fake news article:\\n')\n",
        "data_train[data_train['label'] == 1].iloc[0]['cleaned_text']"
      ],
      "metadata": {
        "id": "NjlrxtHbtfT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "O7ohlrNYeGts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the word cloud\n",
        "all_words = ' '.join(data_train['cleaned_text'])\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Word Cloud - All Training Articles\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l4rNmIL0fsbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequently occurring words\n",
        "tokens = nltk.word_tokenize(all_words)\n",
        "unigram_freq = Counter(tokens)\n",
        "common_unigrams = unigram_freq.most_common(20)\n",
        "unigrams_df = pd.DataFrame(common_unigrams, columns=['Unigram', 'Frequency'])\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='Frequency', y='Unigram', data=unigrams_df)\n",
        "plt.title(\"Top 20 Unigrams\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ev8Lg40Ug2sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequently occurring bigrams\n",
        "bigram_freq = Counter(ngrams(tokens, 2))\n",
        "common_bigrams = bigram_freq.most_common(20)\n",
        "bigrams_df = pd.DataFrame(common_bigrams, columns=['Bigram', 'Frequency'])\n",
        "bigrams_df['Bigram'] = bigrams_df['Bigram'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='Frequency', y='Bigram', data=bigrams_df)\n",
        "plt.title(\"Top 20 Bigrams\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u2TRXmzwg3mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequently occurring trigrams\n",
        "trigram_freq = Counter(ngrams(tokens, 3))\n",
        "common_trigrams = trigram_freq.most_common(20)\n",
        "trigrams_df = pd.DataFrame(common_trigrams, columns=['Trigram', 'Frequency'])\n",
        "trigrams_df['Trigram'] = trigrams_df['Trigram'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='Frequency', y='Trigram', data=trigrams_df)\n",
        "plt.title(\"Top 20 Trigrams\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IgsAhMGUg_EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Cloud for Real News\n",
        "real_news_text = ' '.join(data_train[data_train['label'] == 0]['cleaned_text'])\n",
        "\n",
        "real_news_wordcloud = WordCloud(width = 800, height = 400, background_color = 'white').generate(real_news_text)\n",
        "plt.figure(figsize = (12, 6))\n",
        "plt.imshow(real_news_wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Real News Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8cduPY2JSBu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Cloud for Fake News\n",
        "fake_news_text = ' '.join(data_train[data_train['label'] == 1]['cleaned_text'])\n",
        "\n",
        "fake_news_wordcloud = WordCloud(width = 800, height = 400, background_color = 'white').generate(fake_news_text)\n",
        "plt.figure(figsize = (12, 6))\n",
        "plt.imshow(fake_news_wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Fake News Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NUdggYjzTXJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text length distributions by class\n",
        "data_train['text_length'] = data_train['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize = (10, 5))\n",
        "sns.histplot(data = data_train, x = 'text_length', hue = 'label', kde = True)\n",
        "plt.title('Distribution of Text Length by Class')\n",
        "plt.xlabel('NUmber of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend(title = 'Label', labels = ['Real', 'Fake'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ufnTFOPfT1qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "yla3hPKm0RMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF Vectorisation\n",
        "tfidf = TfidfVectorizer(max_features=5000)"
      ],
      "metadata": {
        "id": "fRWtb1dJwDS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf = tfidf.fit_transform(data_train['cleaned_text'])\n",
        "X_val_tfidf = tfidf.transform(data_val['cleaned_text'])\n",
        "X_test_tfidf = tfidf.transform(data_test['cleaned_text'])"
      ],
      "metadata": {
        "id": "DJ2K_8FZ1MDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = data_train['label']\n",
        "y_val = data_val['label']\n",
        "y_test = data_test['label']"
      ],
      "metadata": {
        "id": "0Fk2fl7b1YF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression (for baseline) on TF-IDF"
      ],
      "metadata": {
        "id": "24dXuf8u4VwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Training Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "hTgmTtmC4wbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on Validation set\n",
        "y_pred_val_tfidf = log_reg.predict(X_val_tfidf)"
      ],
      "metadata": {
        "id": "uPisUd204_dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "print('Validation Data Evaluation (Logistic Regression):\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_val, y_pred_val_tfidf)}')\n",
        "print('\\nClassification Report:\\n')\n",
        "print(classification_report(y_val, y_pred_val_tfidf))"
      ],
      "metadata": {
        "id": "-QORwKCq5F27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cmat = confusion_matrix(y_val, y_pred_val_tfidf)\n",
        "cmat"
      ],
      "metadata": {
        "id": "JBoWTC-g5Njd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cmat, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix on Validation Data (Log Reg)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dSat_8Uo5iAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Bigrams and Trigrams in TF-IDF"
      ],
      "metadata": {
        "id": "BHEdW9dE6QJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF with Bigrams and Trigrams\n",
        "tfidf_ngram = TfidfVectorizer(max_features=10000, ngram_range=(1,3))\n",
        "# ngram_range=(1,3) means unigrams, bigrams and trigrams\n",
        "\n",
        "X_train_ngram = tfidf_ngram.fit_transform(data_train['cleaned_text'])\n",
        "X_val_ngram = tfidf_ngram.transform(data_val['cleaned_text'])\n",
        "X_test_ngram = tfidf_ngram.transform(data_test['cleaned_text'])"
      ],
      "metadata": {
        "id": "-b1tGZVG5pan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression on TF-IDF with Bigram and Trigram"
      ],
      "metadata": {
        "id": "Ue9n9Txi7VhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Logistic Regression on TF-IDF N-grams data\n",
        "log_reg.fit(X_train_ngram, y_train)"
      ],
      "metadata": {
        "id": "xEE74mnq6rn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on Validation Set\n",
        "y_pred_val_ngram = log_reg.predict(X_val_ngram)"
      ],
      "metadata": {
        "id": "EgYsSUxD7lSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print('Validation Data Evaluation (Log Reg with Bigrams/Trigrams):\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_val, y_pred_val_ngram)}')\n",
        "print('\\nClassification Report:\\n')\n",
        "print(classification_report(y_val, y_pred_val_ngram))"
      ],
      "metadata": {
        "id": "IMG-DG2m7qFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cmat_ngram = confusion_matrix(y_val, y_pred_val_ngram)\n",
        "cmat_ngram"
      ],
      "metadata": {
        "id": "GL2XcK4n7wjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cmat_ngram, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix on Validation Set (n-grams)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZVqehNmQ71GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running on test data\n",
        "\n",
        "y_test_pred_ngram = log_reg.predict(X_test_ngram)\n",
        "\n",
        "print('Test Set Evaluation (Log Reg w/ n-grams):\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_test_pred_ngram)}')\n",
        "print(\"\\nTest Set Performance (with Bigrams/Trigrams):\")\n",
        "print(classification_report(y_test, y_test_pred_ngram))\n",
        "print()"
      ],
      "metadata": {
        "id": "NfG3AABf7-Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix for test data\n",
        "cmat_test = confusion_matrix(y_test, y_test_pred_ngram)\n",
        "cmat_test"
      ],
      "metadata": {
        "id": "FThJErOWm8Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cmat_test, annot=True, fmt='d', cmap='Purples', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix on Test Set (n-grams)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EmzpIOn3nB8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "e7qMWGGyOqpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Training SVM model\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train_ngram, y_train)"
      ],
      "metadata": {
        "id": "TaSb5cLynGwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on val set\n",
        "y_pred_val_svm = svm_model.predict(X_val_ngram)"
      ],
      "metadata": {
        "id": "vU2DtM1JQHz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation Data Evaluation (SVM):\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_val, y_pred_val_svm)}')\n",
        "print('\\nClassification Report:\\n')\n",
        "print(classification_report(y_val, y_pred_val_svm))"
      ],
      "metadata": {
        "id": "x8761IstQO0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for validation set\n",
        "cmat_svm = confusion_matrix(y_val, y_pred_val_svm)\n",
        "cmat_svm"
      ],
      "metadata": {
        "id": "nu5T3bqYQZbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cmat_svm, annot=True, fmt='d', cmap='Greens', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - SVM (Validation Set)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uwkiQhOBQ3tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on test set\n",
        "y_pred_test_svm = svm_model.predict(X_test_ngram)"
      ],
      "metadata": {
        "id": "VWfvOkjCQ7Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Data Evaluation (SVM):\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred_test_svm)}')\n",
        "print('\\nClassification Report:\\n')\n",
        "print(classification_report(y_test, y_pred_test_svm))"
      ],
      "metadata": {
        "id": "E3Z_3uYBUQXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for test set\n",
        "cmat_svm_test = confusion_matrix(y_test, y_pred_test_svm)\n",
        "cmat_svm_test"
      ],
      "metadata": {
        "id": "-i82oVDNUeMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cmat_svm_test, annot=True, fmt='d', cmap='Greens', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - SVM (Test Set)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KEeZcYZuU4Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "iV0iRKmPVC5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Training the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_ngram, y_train)"
      ],
      "metadata": {
        "id": "D5eAMCulU8UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on Validation set\n",
        "y_pred_val_nb = nb_model.predict(X_val_ngram)"
      ],
      "metadata": {
        "id": "5sTAwWYqVTbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation Data Evaluation (Naive Bayes):\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_val, y_pred_val_nb)}')\n",
        "print('\\nClassification Report:\\n')\n",
        "print(classification_report(y_val, y_pred_val_nb))"
      ],
      "metadata": {
        "id": "oFtGKnbjVgaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cmat_nb = confusion_matrix(y_val, y_pred_val_nb)\n",
        "cmat_nb"
      ],
      "metadata": {
        "id": "R3fb5JQZVos0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cmat_nb, annot=True, fmt='d', cmap='Oranges', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - Na√Øve Bayes (Validation Set)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fa8KF1KfVyAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Data for LSTM"
      ],
      "metadata": {
        "id": "NnW5w5nXWkQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "JX-yufQDbmbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum vocabulary size (number of unique words to consider)\n",
        "VOCAB_SIZE = 10000\n",
        "# How long each input will be pad/cut\n",
        "MAX_SEQ_LEN = 300"
      ],
      "metadata": {
        "id": "fSTv9Vhbb5v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initiallising tokeniser\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(data_train['cleaned_text'])"
      ],
      "metadata": {
        "id": "olWqaPxrcGVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Texts to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(data_train['cleaned_text'])\n",
        "X_val_seq = tokenizer.texts_to_sequences(data_val['cleaned_text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(data_test['cleaned_text'])"
      ],
      "metadata": {
        "id": "4R0UWI-scmH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to same length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQ_LEN, padding='post', truncating='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_SEQ_LEN, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQ_LEN, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "899Z_X0ZdH4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = data_train['label']\n",
        "y_val = data_val['label']\n",
        "y_test = data_test['label']"
      ],
      "metadata": {
        "id": "Rb7UkEFAevPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sizes of the pad sequence datasets\n",
        "print(f\"Training set shape: {X_train_pad.shape}\")\n",
        "print(f\"Validation set shape: {X_val_pad.shape}\")\n",
        "print(f\"Test set shape: {X_test_pad.shape}\")"
      ],
      "metadata": {
        "id": "oA41-uBdeyp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building and Training the LSTM Model"
      ],
      "metadata": {
        "id": "MES2XbhdgbrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "ACjVG4KRggnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the LSTM model\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=128, input_length=MAX_SEQ_LEN),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "D7IqT_nviHlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "lstm_model.summary()"
      ],
      "metadata": {
        "id": "gnVzIZFrjZLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = lstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val_pad, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "InPRPdKsjgJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of LSTM on Test Set\n",
        "test_loss, test_accuracy = lstm_model.evaluate(X_test_pad, y_test, verbose=2)\n",
        "\n",
        "print(\"LSTM Performance: \")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "k00Ty7jdnBMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bidirectional LSTM"
      ],
      "metadata": {
        "id": "q1W7uvJfsQ2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# Defining the model\n",
        "bilstm_model = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=128, input_length=MAX_SEQ_LEN),\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#Compile\n",
        "bilstm_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "M--UCs5GnCim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "bilstm_model.summary()"
      ],
      "metadata": {
        "id": "uXR5PZ8YuOLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history_bilstm = bilstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val_pad, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "yPu4K0vmuRle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating Bidirectional LSTM on test set\n",
        "test_loss_bilstm, test_accuracy_bilstm = bilstm_model.evaluate(X_test_pad, y_test, verbose=2)\n",
        "\n",
        "print(\"Bidirectional LSTM Performance: \")\n",
        "print(f\"Test Accuracy: {test_accuracy_bilstm:.4f}\")\n",
        "print(f\"Test Loss: {test_loss_bilstm:.4f}\")\n"
      ],
      "metadata": {
        "id": "k0FPTG7WutVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec with LSTM"
      ],
      "metadata": {
        "id": "D46H19rmV24C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading GloVe 100D\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "7V6XB3yzV9AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading GloVe into a dictionary\n",
        "embedding_idx = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf8') as f:\n",
        "  for line in f:\n",
        "    vals = line.split()\n",
        "    word = vals[0]\n",
        "    vector = np.asarray(vals[1:], dtype='float32')\n",
        "    embedding_idx[word] = vector\n",
        "\n",
        "print(f'Loaded {len(embedding_idx)} word vectors from GloVe')"
      ],
      "metadata": {
        "id": "F3eWp-kYWU_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Embedding Matrix\n",
        "\n",
        "# dimensions\n",
        "EMBEDDING_DIM = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(VOCAB_SIZE, len(word_index) + 1)\n",
        "\n",
        "# Initialising matrix with zeros\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "# Filling matrix with GloVe vectors\n",
        "for word, i in word_index.items():\n",
        "  if i < num_words:\n",
        "    embedding_vector = embedding_idx.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "FGERAdrEXAtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building LSTM with GloVe - Frozen\n",
        "\n",
        "lstm_glove_frozen = Sequential([\n",
        "    Embedding(input_dim = num_words,\n",
        "              output_dim = EMBEDDING_DIM,\n",
        "              weights = [embedding_matrix],\n",
        "              input_length = MAX_SEQ_LEN,\n",
        "              trainable = False),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "QoZ3cJx_YUvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "lstm_glove_frozen.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "1UpAK65Kq3kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history_glove = lstm_glove_frozen.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs = 5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val_pad, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "7cYHvk9CrNSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating on test set\n",
        "test_loss_glove, test_acc_glove = lstm_glove_frozen.evaluate(X_test_pad, y_test, verbose = 2)\n",
        "\n",
        "print(\"GloVe LSTM (Frozen) Performance: \")\n",
        "print(f'Test Accuracy: {test_acc_glove:.4f}')\n",
        "print(f'Test Loss: {test_loss_glove:.4f}')"
      ],
      "metadata": {
        "id": "EYpNpq-3u_0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building LSTM with GloVe - Trainable\n",
        "\n",
        "lstm_glove_trainable = Sequential([\n",
        "    Embedding(input_dim = num_words,\n",
        "              output_dim = EMBEDDING_DIM,\n",
        "              weights = [embedding_matrix],\n",
        "              input_length = MAX_SEQ_LEN,\n",
        "              trainable = True),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "3iJeL1FDMRYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "lstm_glove_trainable.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "QV0lGIKxMnBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history_glove1 = lstm_glove_trainable.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs = 5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val_pad, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "YQAdc4KCMpds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating on test set\n",
        "test_loss_glove, test_acc_glove = lstm_glove_trainable.evaluate(X_test_pad, y_test, verbose = 2)\n",
        "\n",
        "print(\"GloVe LSTM (Trainable) Performance: \")\n",
        "print(f'Test Accuracy: {test_acc_glove:.4f}')\n",
        "print(f'Test Loss: {test_loss_glove:.4f}')"
      ],
      "metadata": {
        "id": "Ck9PiStdM2EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe + BiLSTM"
      ],
      "metadata": {
        "id": "jsZnyW1mD6pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Bidirectional LSTM with GloVe - Frozen\n",
        "bilstm_glove_frozen = Sequential([\n",
        "    Embedding(\n",
        "        input_dim = num_words,\n",
        "        output_dim = EMBEDDING_DIM,\n",
        "        weights = [embedding_matrix],\n",
        "        input_length = MAX_SEQ_LEN,\n",
        "        trainable = False),\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "LStepcDQDzfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "bilstm_glove_frozen.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "LcAEJgnREyot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history_bilstm_glove = bilstm_glove_frozen.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs = 5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val_pad, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "zSJF30D_E2sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test set\n",
        "test_loss_bilstm_glove, test_acc_bilstm_glove = bilstm_glove_frozen.evaluate(X_test_pad, y_test, verbose = 2)\n",
        "\n",
        "print(\"BiLSTM + GloVe (Frozen) Performance: \")\n",
        "print(f'Test Accuracy: {test_acc_bilstm_glove:.4f}')\n",
        "print(f'Test Loss: {test_loss_bilstm_glove:.4f}')\n"
      ],
      "metadata": {
        "id": "j0RValuvE-U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Bidirectional LSTM with GloVe - Trainable\n",
        "bilstm_glove_trainable = Sequential([\n",
        "    Embedding(\n",
        "        input_dim = num_words,\n",
        "        output_dim = EMBEDDING_DIM,\n",
        "        weights = [embedding_matrix],\n",
        "        input_length = MAX_SEQ_LEN,\n",
        "        trainable = True),\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "ieluhGP5OWgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "bilstm_glove_trainable.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "G4gA7xEUOmwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history_bilstm_glove = bilstm_glove_trainable.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs = 5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val_pad, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "J2KeqY5YOsXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test set\n",
        "test_loss_bilstm_glove, test_acc_bilstm_glove = bilstm_glove_trainable.evaluate(X_test_pad, y_test, verbose = 2)\n",
        "\n",
        "print(\"BiLSTM + GloVe (Trainable) Performance: \")\n",
        "print(f'Test Accuracy: {test_acc_bilstm_glove:.4f}')\n",
        "print(f'Test Loss: {test_loss_bilstm_glove:.4f}')\n"
      ],
      "metadata": {
        "id": "YyXt3bAoPhFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error Analysis**"
      ],
      "metadata": {
        "id": "nEmM4sZhHNYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for printing confusion matrix\n",
        "def plot_conf_matrix(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "wx9x1fIfYzp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with SVM\n",
        "y_pred_svm = svm_model.predict(X_test_ngram)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_conf_matrix(y_test, y_pred_svm, title=\"Confusion Matrix - SVM (TF-IDF with n-gram)\")\n"
      ],
      "metadata": {
        "id": "BErI5AE3ZrR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with BiLSTM\n",
        "y_pred_bilstm_glove = (bilstm_glove_trainable.predict(X_test_pad) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_conf_matrix(y_test, y_pred_bilstm_glove, title=\"Confusion Matrix - GloVe + BiLSTM (Trainable)\")\n"
      ],
      "metadata": {
        "id": "0_RBIO2XZt9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_misclassified_examples(y_true, y_pred, texts, max_examples=25, model_name=\"Model\"):\n",
        "    errors = (y_true != y_pred)\n",
        "    misclassified_indices = [i for i, wrong in enumerate(errors) if wrong]\n",
        "    print(f\"=== Misclassified Examples ({model_name}) ===\")\n",
        "    for i in misclassified_indices[:max_examples]:\n",
        "        print(f\"\\n--- Example #{i} ---\")\n",
        "        print(f\"Actual Label: {y_true[i]} | Predicted Label: {y_pred[i]}\")\n",
        "        print(f\"Text:\\n{texts.iloc[i][:200]}...\")  # Shortened output for readability\n"
      ],
      "metadata": {
        "id": "pH3fK0M8Zy4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_misclassified_examples(y_test, y_pred_svm, data_test['text'], model_name=\"SVM (TF-IDF with N-Grams)\")"
      ],
      "metadata": {
        "id": "Z084Kfc_Z6Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_misclassified_examples(y_test, y_pred_bilstm_glove, data_test['text'], model_name=\"GloVe + BiLSTM (Trainable)\")"
      ],
      "metadata": {
        "id": "45q4oR3_aCBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the models"
      ],
      "metadata": {
        "id": "YEPTo3De_oJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(tfidf_ngram, '/content/drive/MyDrive/NLP_Coursework/tfidf_ngram.pkl')\n",
        "joblib.dump(svm_model, '/content/drive/MyDrive/NLP_Coursework/svm_model.pkl')"
      ],
      "metadata": {
        "id": "6Y-yJN1waJX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_glove_trainable.save('/content/drive/MyDrive/NLP_Coursework/bilstm_glove_trainable.h5')"
      ],
      "metadata": {
        "id": "H3wHTlbhCvUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP_Coursework/tokenizer.pkl', 'wb') as f:\n",
        "  pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "YzZyfCDIDB0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/NLP_Coursework/max_len.txt', 'w') as f:\n",
        "  f.write(str(MAX_SEQ_LEN))"
      ],
      "metadata": {
        "id": "Qg19CMIPDY8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOeQprSTDliG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}